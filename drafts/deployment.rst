Deploying Software
==================

:date: 2013-01-01
:category: workflow
:summary:

Deployment is the process of getting a program installed and configured on
each computer that needs it.

Doing that also requires installing all dependencies - programs it depends on,
libraries it depends on, and configuration to make it behave correctly on the
target machine.

https://zachholman.com/posts/deploying-software has a ton of good info about
this process.

https://blog.philipphauer.de/databases-challenge-continuous-delivery/ touches
on the complexities of zero-downtime deployments with database schema changes.
I haven't tried the approach myself but it sounds about right.

------------------

For years I thought a static website needed only to use the 'symlink swap'
trick to change its docroot for fully robust releases:
http://blog.moertel.com/posts/2005-08-22-how-to-change-symlinks-atomically.html

As I pondered how the release process for Scriptlighter.com should work, I
realized I was dead wrong.

Using that trick to change a project's docroot should mean no requests get
lost.

However, if we respond to a request for '/' (or any HTML document) immediately
before the symlink swap, the user agent will send out a number of requests for
embedded resources as the symlink swap commences and runs.

Thus, one request for '/styles.css' might be served from the old docroot while
the following request for '/overrides.css' might be served from the new one,
which means the user will see a broken, inconsistent page.

I want to figure out how to prevent that.

I've been toying with multiple weird ideas while ignoring a straightforward one
because it felt ugly to me.

I'm going back to it because I found someone who solved the problem with
roughly the approach I've been ignoring:

http://rea.tech/static-assets-in-an-eventually-consistent-webapp-deployment/

That approach is, of course, storing your static assets under a hash of their
contents.

If you render your static pages to use those asset names appropriately, then as
long as you leave the old deployment's assets available under the appropriate
hash, requests generated by an old URL can be satisfied even though the new
site is live.

Why does that feel ugly to me?

- If you throw the assets under a single hashed 'assets' dir, you break client
  and proxy caching needlessly, as most assets won't change between
  deployments.

- Defining a page template becomes more complex, as you must use an abstraction
  to refer to static assets.

- Including images in a page requires the content manager to know about the
  asset() abstraction we would be forced to add.

- I feel that user-visible URLs with hashes in them are ugly. They're hard to
  read, hard to say, hard to remember, hard to type, and they don't look nice.

For the first item, if assets are stored under their individual hashes, then
caching will not be broken for assets that remain unchanged between releases.

The increased complexity of using an asset() call to reference assets can't be
avoided *if* you do something like the above paragraph. If you don't, then you
could store everything under a commit hash directory and use a <base> tag to
change which assets you're loading.

The URLs being ugly is not a big deal. I don't love it, but in practice people
who notice URLs copy and paste them.



It's somewhat off-topic, but I feel the need to observe that serving up the
individual hash directories is closely related to leaving a public history of
published versions of the site.

Also interesting is the fact that it's pretty trivial to add, update, or remove
the <base> tag to all pages across an instance of the site, since there should
only be one per document and it has to be in the <head> section of the doc.




A multi-phase deployment of some kind seems like it could solve this problem,
too.

Start by redirecting all inbound requests for naked paths (e.g.
'/work/projects/') or .html files (e.g. '/index.html') to URLs prefixed with an
explicit version identifier (e.g. '/release-804ba2/work/projects/' or
'/release-804ba2/index.html').

The explicit-version instance of the site uses a <base> tag to ensure that all
resources loaded by an HTML file are the matching version (and also that links
followed to new HTML pages keep people on the appropriate site).

After N seconds (or perhaps N seconds without a request that passes through the
redirect, as that implies active users have been transitioned over to the
hashed URLs), we do the symlink dance to switch naked URLs/.html files over to
the new release then stop redirecting people to the explicitly-hashed site
instance.

Finally, we fire up the inverse redirect - redirect all requests beginning with
'/release-804ba2/' to a URL that doesn't have them, so that any users who are
browsing on the old version of the site get sent back to the newly-released
version.
